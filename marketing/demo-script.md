# Scenery Demo Script (2:30)

**Engineer-to-Engineer • Technically Accurate**

---

## AI-GENERATED HOOK (0:00 - 0:22)

**VOICEOVER (AI-generated video playing):**
"With Google AI Studio, you can vibe code an entire app in a couple of seconds! But the moment someone asks to make a product video for it—you're back in the stone age. You screen record, edit frame by frame, and do it all over again every single time you push an update. That's why I built Scenery. Just connect your GitHub repo and WATCH as Gemini turns your real components into videos. No re-recording, no re-editing—JUST AUTOMATIC."

---

## FACE CAM: INTRO (0:22 - 0:35)

**YOU:**
"That video was generated by Gemini 3. Two pipelines, seven AI integrations, running on Fly.io with a dedicated Playwright worker. Let me walk you through what I actually built."

---

## PIPELINE 1: COMPONENT DISCOVERY (0:35 - 1:10)

### Architecture (0:35 - 0:55)

**YOU (screen share - architecture diagram):**
"First pipeline: component discovery. You give me a GitHub URL."

**SCREEN:**
```
COMPONENT DISCOVERY PIPELINE
────────────────────────────
GitHub URL
    ↓
Clone + AST Parse (react-docgen-typescript)
    → Extract props, types, JSDoc descriptions
    ↓
Content Hash (SHA-256)
    → Only re-process changed files
    ↓
[Gemini] Categorize Component
    → JSON Schema output: category, videoRole, deviceFrame suggestion
    → Uses Zod schemas converted to JSON Schema
    ↓
[Gemini] Generate Demo Props
    → Realistic values with confidence scores
    → Interactive element extraction (CSS selectors)
    ↓
Server Component Detection (172 patterns)
    → Prisma, NextAuth, Drizzle, Clerk, Node builtins...
    ↓
[Gemini] Pure React Transform
    → Removes ALL external imports
    → next/link → <a>, next/image → <img>
    → lucide-react → inline SVG
    → Server actions → mock functions
    ↓
Playwright Worker (Fly.io)
    → Real browser render with hooks, state, effects
    → 4-attempt recovery with AI error analysis
    ↓
[Gemini] Tailwind → Inline CSS
    → Uses extended thinking mode (10k token budget)
    ↓
Component Previews + Interactive Elements
```

**YOU:**
"The key insight: Next.js Server Components crash in the browser—they use async/await, database calls, Node APIs. So I built a detection system with 172 regex patterns for Prisma, NextAuth, Drizzle, Clerk, all the Node builtins. When we detect one, Gemini transforms it to a client-safe version. Removes the awaits, mocks the data, strips the auth guards. Then Playwright renders it in real Chromium—not mocked HTML, actual React with hooks and state."

**YOU (continuing):**
"For the AI calls, I'm using Gemini's structured output with explicit JSON schemas. I define the exact shape I want using Zod, convert it to JSON Schema, and Gemini returns typed data every time. Near-zero malformed outputs."

### Live Demo (0:55 - 1:10)

**YOU:**
"Let me show you."

**SCREEN:**
```
0:55-1:00
- Click into project
- Click "Connect GitHub"
- Paste repo URL, loading starts
```

**YOU:**
"It's cloning, parsing, running through Gemini..."

**SCREEN:**
```
1:00-1:08
- Components populate grid
- Click a component
- Show props panel with "AI Generated" badge
```

**YOU:**
"Every component gets categorized with a confidence score, demo props generated, real preview rendered. And the system extracts interactive elements—buttons, inputs—with CSS selectors for cursor targeting in videos."

---

## PIPELINE 2: VIDEO GENERATION (1:10 - 1:50)

### Architecture (1:10 - 1:28)

**YOU:**
"Now the video pipeline. This is a four-agent system using Gemini's function calling."

**SCREEN:**
```
VIDEO GENERATION PIPELINE (Multi-Agent)
───────────────────────────────────────
User Prompt: "Create a demo of our auth flow"
    ↓
[Gemini] DIRECTOR AGENT
    → Function: create_video_plan
    → Outputs: title, tone, style, scene breakdown
    → Scene intents: "dramatic entrance", NOT "spring-scale bouncy"
    → Frame budget: Hook(15%) → Setup(15%) → Showcase(55%) → CTA(15%)
    ↓
[Gemini] SCENE PLANNER (parallel per scene)
    → Function: create_detailed_scene
    → Translates intent → concrete animations
    → Element positions (1920×1080 canvas math)
    → Spring configs: damping, stiffness, mass
    → Cursor paths with CSS selectors
    → CRITICAL: All keyframes RELATIVE to element start
    ↓
ASSEMBLY AGENT (deterministic, no LLM)
    → Converts relative → absolute frames
    → Builds tracks with z-index ordering
    → Pure TypeScript transformation
    ↓
[Gemini] REFINEMENT AGENT ←──────────────┐
    → Function: analyze_composition       │
    → Scores 0-100 across 5 categories:   │
      • Visual Composition (30%)          │
      • Timing (25%)                      │
      • Narrative Flow (25%)              │
      • Animation Quality (15%)           │
      • Accessibility (5%)                │
    → Score < 40: Regenerate from Director│
    → Score 40-74: Apply patches ─────────┘
    → Score 75+: Ship it
    ↓
Remotion Export (MP4/WebM)
```

**YOU:**
"Director plans the narrative—hook, features, call-to-action. Outputs scene intents, not animation specifics. Scene Planner runs in parallel for each scene, using function calling to set exact positions, spring physics, cursor paths. Assembly is pure TypeScript—no LLM, just deterministic transformation. Then Refinement Agent scores it zero to a hundred across five weighted categories."

### Live Demo (1:28 - 1:50)

**YOU:**
"Watch this."

**SCREEN:**
```
1:28-1:33
- In editor, select 2-3 components
- Type: "Create a product demo of our auth flow"
- Click generate
```

**YOU:**
"Four agents coordinating through function calls..."

**SCREEN:**
```
1:33-1:45
- Progress messages:
  → "Director: planning video structure..."
  → "Scene Planner: 5 scenes in parallel..."
  → "Assembly: building composition..."
  → "Refinement: 72/100 → applying 3 patches..."
  → "Refinement: 85/100 ✓"
- Video preview appears
```

**YOU:**
"Seventy-two first pass—below threshold. It identifies three issues, applies patches, re-evaluates. Eighty-five. Most AI tools are one-shot—you get output, regenerate if it's wrong. Here the system critiques and fixes itself through function calling."

**SCREEN:**
```
1:45-1:50
- Play generated video in preview
- Spring animations visible
```

**YOU:**
"And those spring animations—five presets: smooth, snappy, heavy, bouncy, gentle. Each maps to Remotion's damping, stiffness, mass values. Frame-accurate, deterministic rendering."

---

## AUTO-SYNC (1:50 - 2:12)

**YOU:**
"But here's what makes this useful for real teams."

**SCREEN:**
```
1:50-1:58
- Type in chat: "Slow down the transitions"
- Video updates
```

**YOU:**
"You can keep iterating—the AI applies targeted patches, not full regeneration."

**SCREEN:**
```
1:58-2:05
- Click sync button
- "Syncing..." → "2 components updated"
```

**YOU:**
"When you push to your repo, click sync. The system computes content hashes, diffs against the database, only re-runs AI on changed components. Videos reference live component HTML—they update automatically."

**SCREEN:**
```
2:05-2:12
- Preview refreshes
```

**YOU:**
"No re-recording. No re-editing. Documentation that actually stays current."

---

## CLOSING (2:12 - 2:30)

**YOU (face cam or screen):**
"So that's Scenery. Seven Gemini integrations. Structured output with JSON schemas for typed responses. Function calling for agent orchestration. Extended thinking for complex HTML transformations. Two pipelines—component discovery and video generation—coordinated through a refinement loop that scores and self-corrects. Deployed on Fly with a dedicated Playwright worker. Open source."

**SCREEN:**
```
2:20-2:30
- Architecture diagram with all Gemini nodes highlighted
- "Built with Gemini 3 + Remotion"
- URL: scenery-gemini3.fly.dev
```

---

## TIMING SUMMARY

| Section | Duration | End Time |
|---------|----------|----------|
| AI-Generated Hook | 22s | 0:22 |
| Face Cam Intro | 13s | 0:35 |
| Pipeline 1: Architecture | 20s | 0:55 |
| Pipeline 1: Demo | 15s | 1:10 |
| Pipeline 2: Architecture | 18s | 1:28 |
| Pipeline 2: Demo | 22s | 1:50 |
| Auto-Sync | 22s | 2:12 |
| Closing | 18s | 2:30 |
| **Total** | **2:30** | |

---

## TECHNICAL ACCURACY CHECKLIST

### Component Discovery (verified from code)
- [ ] **172 patterns** for server component detection (not 190)
- [ ] react-docgen-typescript for AST parsing
- [ ] SHA-256 content hashing for cache invalidation
- [ ] Zod schemas → JSON Schema for Gemini structured output
- [ ] 3-tier preview: Playwright → SSR → AI-only
- [ ] Extended thinking (10k token budget) in AI-only fallback
- [ ] 4-attempt recovery with AI error analysis
- [ ] Interactive element extraction with CSS selectors

### Video Generation (verified from code)
- [ ] 4 agents: Director → Scene Planner (parallel) → Assembly → Refinement
- [ ] **Assembly is pure TypeScript** (no LLM)
- [ ] All agents use **function calling** (create_video_plan, create_detailed_scene, analyze_composition)
- [ ] 5 scoring categories with weights (Visual 30%, Timing 25%, Narrative 25%, Animation 15%, Accessibility 5%)
- [ ] Score thresholds: <40 regenerate, 40-74 patch, 75+ ship
- [ ] 5 spring presets: smooth, snappy, heavy, bouncy, gentle
- [ ] **CRITICAL**: Keyframes are RELATIVE to element start (frame 0 = when element appears)
- [ ] Frame budget formula: Hook(15%) → Setup(15%) → Showcase(55%) → CTA(15%)

### Gemini Features Used
- [ ] **Structured Output** - responseMimeType: 'application/json' + responseSchema
- [ ] **Function Calling** - for all agent tools
- [ ] **Extended Thinking** - thinkingBudget: 10000 in AI-only preview
- [ ] **Long Context** - full source code (up to 10k chars)
- [ ] Zod → JSON Schema conversion

---

## WHAT MAKES THIS TECHNICALLY IMPRESSIVE

1. **Multi-Agent Orchestration** - Not just one prompt, four specialized agents with function calling
2. **Self-Correcting Loop** - Refinement agent scores and patches, system improves itself
3. **Server Component Detection** - 172 patterns covering entire Next.js ecosystem
4. **3-Tier Preview Fallback** - Playwright for real rendering, SSR for simplicity, AI for pure generation
5. **Content-Hash Caching** - Only re-process what changed (efficient incremental updates)
6. **Typed AI Outputs** - Zod schemas ensure structured, validated responses
7. **Spring Physics** - Professional motion with Remotion's damping/stiffness/mass system
8. **Frame-Relative Keyframes** - Prevents 80% of animation timing bugs

---

## KEY LINES TO NAIL

**On Structured Output:**
"I'm using Gemini's structured output with explicit JSON schemas. I define the exact shape using Zod, convert it to JSON Schema, and Gemini returns typed data every time."

**On Function Calling:**
"Each agent has its own function tool—Director calls create_video_plan, Scene Planner calls create_detailed_scene, Refinement calls analyze_composition."

**On the Refinement Loop:**
"Seventy-two first pass. It identifies issues, applies patches, re-evaluates. Most AI tools are one-shot. Here the system critiques and fixes itself."

**On Server Components:**
"172 patterns for Prisma, NextAuth, Drizzle, Clerk, all the Node builtins. When we detect one, Gemini transforms it to client-safe."

**On the Architecture:**
"Four agents. Director outputs intents, not animations. Scene Planner translates to positions and spring configs. Assembly is pure TypeScript—no LLM. Refinement scores and patches."
